{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stroke column go end\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv('misss_final.csv')\n",
    "import csv\n",
    "\n",
    "\n",
    "syc=0\n",
    "miss_final_reg = []\n",
    "with open(\"misss_final.csv\", \"r\", newline=\"\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    for miss_final_regular  in csvreader:\n",
    "        syc=syc+1\n",
    "        miss_final_reg.append([ miss_final_regular [1], miss_final_regular [2],miss_final_regular [3], miss_final_regular [4], miss_final_regular [5],miss_final_regular [6], miss_final_regular [7], miss_final_regular [8],miss_final_regular [9], miss_final_regular [12], miss_final_regular [11], miss_final_regular [10]])\n",
    "        if syc==1:\n",
    "            field=miss_final_reg\n",
    "            print(\"miss_regular_file.csv\",field[0])\n",
    "\n",
    "\n",
    "with open('miss_regular_file.csv', 'w') as f:\n",
    "\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(field[0])\n",
    "    write.writerows(miss_final_reg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv('miss_regular_file.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "S_all=data\n",
    "S_all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "S_all['gender']= label_encoder.fit_transform(S_all['gender'])\n",
    "S_all['ever_married']= label_encoder.fit_transform(S_all['ever_married'])\n",
    "S_all['work_type']= label_encoder.fit_transform(S_all['work_type'])\n",
    "S_all['Residence_type']= label_encoder.fit_transform(S_all['Residence_type'])\n",
    "S_all['avg_glucose_level']= label_encoder.fit_transform(S_all['avg_glucose_level'])\n",
    "data=S_all\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "syc=0\n",
    "df = data\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "#Implementing cross validation\n",
    "#lab = preprocessing.LabelEncoder()\n",
    "#y= lab.fit_transform(y)\n",
    "k = 3\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    syc=syc+1\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "    train1=X_train.join(y_train, how='right')\n",
    "    test1=X_test.join(y_test, how='right')\n",
    "    train1.to_csv(\"train{}.csv\".format(syc))\n",
    "    test1.to_csv(\"test{}.csv\".format(syc))\n",
    "\n",
    "\n",
    "    print(\"completed csv files train and test\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate train files stroke and unstroke\n",
    "import pandas as pd\n",
    "#TRAIN UNSTROKE SEPERATION\n",
    "for i in range(k):\n",
    "    df = pd.read_csv(\"train{}.csv\".format(i+1))\n",
    "    df =  df[df.stroke != 1]\n",
    "    df.to_csv(\"train{}_unstroke.csv\".format(i+1), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate train files stroke and unstroke\n",
    "import pandas as pd\n",
    "#TRAIN STROKE SEPERATION\n",
    "for i in range(k):\n",
    "    df = pd.read_csv(\"train{}.csv\".format(i+1))\n",
    "    df =  df[df.stroke != 0]\n",
    "    df.to_csv(\"train{}_stroke.csv\".format(i+1), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate %20 anticore\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "#TRAIN STROKE SEPERATION %20\n",
    "k=3\n",
    "print(k)\n",
    "print(k)\n",
    "\n",
    "syc=0\n",
    "syc_second=0\n",
    "syc_third=0\n",
    "stroke_20=[]\n",
    "for i in range(k):\n",
    "\n",
    "\n",
    "    dft = pd.read_csv(\"train{}_stroke.csv\".format(i+1))\n",
    "    ldft=len(dft)\n",
    "    print(\"len{}=\".format(i+1),ldft)\n",
    "    new_ldft=math.ceil(0.2*ldft)\n",
    "    print(new_ldft)\n",
    "    ####################%20 create#################################################\n",
    "\n",
    "    print(\"iiiiii\",new_ldft)\n",
    "    csvfile = open(\"train{}_stroke.csv\".format(i+1), 'r').readlines()\n",
    "    for t in range(len(csvfile)):\n",
    "        if t % new_ldft == 0:\n",
    "            print(\"start\")\n",
    "            open(\"train{}_stroke_20.csv\".format(i+1), 'w+').writelines(csvfile[t:t+new_ldft])\n",
    "            open(\"train{}_stroke_80.csv\".format(i+1), 'w+').writelines(csvfile[0:t])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate %20 anticore\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "#TRAIN UNSTROKE SEPERATION %20\n",
    "k=3\n",
    "print(k)\n",
    "print(k)\n",
    "\n",
    "syc=0\n",
    "syc_second=0\n",
    "syc_third=0\n",
    "stroke_20=[]\n",
    "for i in range(k):\n",
    "\n",
    "\n",
    "    dft = pd.read_csv(\"train{}_unstroke.csv\".format(i+1))\n",
    "    ldft=len(dft)\n",
    "    print(\"len{}=\".format(i+1),ldft)\n",
    "    new_ldft=math.ceil(0.2*ldft)\n",
    "    print(new_ldft)\n",
    "    ####################%20 create#################################################\n",
    "\n",
    "    print(\"iiiiii\",new_ldft)\n",
    "    csvfile = open(\"train{}_unstroke.csv\".format(i+1), 'r').readlines()\n",
    "    for t in range(len(csvfile)):\n",
    "        if t % new_ldft == 0:\n",
    "            print(\"start\")\n",
    "            open(\"train{}_unstroke_20.csv\".format(i+1), 'w+').writelines(csvfile[t:t+new_ldft])\n",
    "            open(\"train{}_unstroke_80.csv\".format(i+1), 'w+').writelines(csvfile[0:t])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#AIS algorithm 6 results preparations\n",
    "!pip install pandas\n",
    "!pip install copy\n",
    "!pip install operator\n",
    "!pip install deap\n",
    "!pip install uuid\n",
    "!pip install unittest\n",
    "!pip install configparser\n",
    "!pip install scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###UTILL\n",
    "import uuid\n",
    "\n",
    "def create_uuid():\n",
    "    return uuid.uuid4()\n",
    "\n",
    "# if (__name__==\"__main__\"):\n",
    "#     print(create_uuid())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###AFFINITY\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def affinity(ag,ab,algo=\"euclidean\"):\n",
    "\n",
    "    if (algo==\"euclidean\"):\n",
    "        return distance.euclidean(float(ag.get_properties_as_list()[1:]),float(ab.get_properties_as_list()[1:]))\n",
    "    elif (algo==\"cosine\"):\n",
    "        return distance.cosine(ag.get_properties_as_list()[1:],ab.get_properties_as_list()[1:])\n",
    "    else:\n",
    "        print(\"invalid selector\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###ANTIBODYYYY\n",
    "# id\n",
    "# gender\n",
    "# age\n",
    "# hypertension\n",
    "# heart_disease\n",
    "# ever_married\n",
    "# work_type\n",
    "# Residence_type\n",
    "# avg_glucose_level\n",
    "# bmi\n",
    "# smoking_status\n",
    "# stroke\n",
    "\n",
    "\n",
    "\n",
    "class Antibody:\n",
    "    def __init__(self,data = []):\n",
    "        self.__id = data[1]\n",
    "        self.__gender = data[2]\n",
    "        self.__age = data[3]\n",
    "        self.__hypertension = data[4]\n",
    "        self.__heart_disease = data[5]\n",
    "        self.__ever_married = data[6]\n",
    "        self.__work_type = data[7]\n",
    "        self.__Residence_type = data[8]\n",
    "        self.__avg_glucose_level = data[9]\n",
    "        self.__smoking_status= data[10]\n",
    "        self.__bmi= data[11]\n",
    "        self.__stroke = data[12]\n",
    "\n",
    "\n",
    "\n",
    "    def clone(self):\n",
    "        without_label = self.get_properties_as_list()\n",
    "        without_label.append(-1)\n",
    "        return Antibody(without_label)\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.__id\n",
    "\n",
    "    def get_gender(self):\n",
    "        return self.__gender\n",
    "\n",
    "    def get_age(self):\n",
    "        return self.__age\n",
    "\n",
    "    def get_hypertension(self):\n",
    "        return self.__hypertension\n",
    "\n",
    "    def get_heart_disease(self):\n",
    "        return self.__heart_disease\n",
    "\n",
    "    def get_ever_married(self):\n",
    "        return self.__ever_married\n",
    "\n",
    "    def get_work_type(self):\n",
    "        return self.__work_type\n",
    "\n",
    "    def get_Residence_type(self):\n",
    "        return self.__Residence_type\n",
    "\n",
    "    def get_avg_glucose_level(self):\n",
    "        return self.__avg_glucose_level\n",
    "\n",
    "    def get_smoking_status(self):\n",
    "        return self.__smoking_status\n",
    "    def get_bmi(self):\n",
    "        return self.__bmi\n",
    "\n",
    "    def get_stroke(self):\n",
    "        return self.__stroke\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_properties_as_list(self):\n",
    "        ls = []\n",
    "        ls.append(self.__id)\n",
    "        ls.append(self.__gender)\n",
    "        ls.append(self.__age)\n",
    "        ls.append(self.__hypertension)\n",
    "        ls.append(self.__heart_disease)\n",
    "        ls.append(self.__ever_married)\n",
    "        ls.append(self.__work_type)\n",
    "        ls.append(self.__Residence_type)\n",
    "        ls.append(self.__avg_glucose_level)\n",
    "        ls.append(self.__smoking_status)\n",
    "        ls.append(self.__bmi)\n",
    "        ls.append(self.__stroke)\n",
    "\n",
    "        return ls\n",
    "\n",
    "    def get_properties_as_list_with_label(self):\n",
    "        without_label = self.get_properties_as_list()\n",
    "        stroke=  self.get_stroke()\n",
    "        without_label.append(stroke)\n",
    "        return without_label\n",
    "\n",
    "    def set_id(self,value):\n",
    "        self.__id = value\n",
    "    id  = property(get_id, set_id)\n",
    "\n",
    "    def set_gender(self,value):\n",
    "        self.__gender = value\n",
    "    gender  = property(get_gender, set_gender)\n",
    "\n",
    "    def set_age(self,value):\n",
    "        self.__age = value\n",
    "    age  = property(get_age, set_age)\n",
    "\n",
    "    def set_hypertension(self,value):\n",
    "        self.__hypertension = value\n",
    "    hypertension  = property(get_hypertension, set_hypertension)\n",
    "\n",
    "    def set_heart_disease(self,value):\n",
    "        self.__heart_disease= value\n",
    "    heart_disease  = property(get_heart_disease, set_heart_disease)\n",
    "\n",
    "    def set_ever_married(self,value):\n",
    "        self.__ever_married = value\n",
    "    ever_married  = property(get_ever_married, set_ever_married)\n",
    "\n",
    "    def set_work_type(self,value):\n",
    "        self.__work_type = value\n",
    "    work_type  = property(get_work_type, set_work_type)\n",
    "\n",
    "    def set_Residence_type(self,value):\n",
    "        self.__Residence_type = value\n",
    "    Residence_type  = property(get_Residence_type, set_Residence_type)\n",
    "\n",
    "    def set_avg_glucose_level(self,value):\n",
    "        self.__avg_glucose_level = value\n",
    "    avg_glucose_level  = property(get_avg_glucose_level, set_avg_glucose_level)\n",
    "    def set_smoking_status(self,value):\n",
    "        self.__smoking_status = value\n",
    "    smoking_status = property(get_smoking_status, set_smoking_status)\n",
    "\n",
    "    def set_bmi(self,value):\n",
    "        self.__bmi = value\n",
    "    bmi = property(get_bmi , set_bmi )\n",
    "\n",
    "    def set_stroke(self,value):\n",
    "        self.__stroke = value\n",
    "    stroke = property(get_stroke, set_stroke)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def hash(self):\n",
    "        pass\n",
    "\n",
    "    def toString(self):\n",
    "        return ( \" [ \"+\"id\"+str(self.__id)+ \"gender\" + str(self.__gender) + 'age' +\n",
    "                 str(self.__age) + 'hypertension' + str(self.__hypertension) + 'heart_disease' +\n",
    "                 str(self.__heart_disease) + 'ever_married'+ str(self.__ever_married) + 'work_type' + str(self.__work_type) +\n",
    "                 'Residence_type' + str(self.__Residence_type) + 'avg_glucose_level' + str(self.__avg_glucose_level) +\n",
    "                  'smoking_status' + str(self.__smoking_status) + 'bmi' + str(self.__bmi ) + 'stroke' + str(self.__stroke)          +\"]\")\n",
    "\n",
    "    def get_all_numeric(self):\n",
    "        return [ self.__id,self.__age,self.__avg_glucose_level,self.__bmi]\n",
    "\n",
    "    def get_all_boolean(self):\n",
    "        return [self.__gender,self.__hypertension,self.__heart_disease,self.__ever_married,self.__stroke]\n",
    "\n",
    "    def set_all_numeric(self, lst):\n",
    "        self.__id=lst[0]\n",
    "        self.__age=lst[1]\n",
    "        self.__avg_glucose_level=lst[2]\n",
    "        self.__bmi=lst[3]\n",
    "\n",
    "    def set_all_boolean(self,lst):\n",
    "        self.__gender=lst[0]\n",
    "        self.__hypertension=lst[1]\n",
    "        self.__heart_disease=lst[2]\n",
    "        self.__ever_married=lst[3]\n",
    "        self.__stroke=lst[4]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###MUTATIONN\n",
    "from deap import tools\n",
    "\n",
    "\n",
    "# from antibody import Antibody\n",
    "\n",
    "def mutateOneAb(Ab, mut_rate):\n",
    "    numAttr = Ab.get_all_numeric()\n",
    "    boolAttr = Ab.get_all_boolean()\n",
    "    # print(tools.mutGaussian(numAttr,0,mut_rate,0.5))\n",
    "    Ab.set_all_numeric(tools.mutGaussian(numAttr, 0, mut_rate, 1)[0])\n",
    "    Ab.set_all_boolean(tools.mutFlipBit(boolAttr, mut_rate)[0])\n",
    "    return Ab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###SAMPLEEEE FİREFLYYYYYY\n",
    "!pip install fireflyalgorithm\n",
    "import numpy as np\n",
    "from fireflyalgorithm import FireflyAlgorithm\n",
    "\n",
    "\n",
    "FA = FireflyAlgorithm()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "def fire_func(x):\n",
    "    return np.sum(x **2)\n",
    "FA = FireflyAlgorithm()\n",
    "r=random.randint(280,330)\n",
    "l=random.uniform(1.5,1.6)\n",
    "Firefly=FA.run(function=fire_func, dim=1, lb=1.5, ub=2, max_evals=330)\n",
    "#clone_firefly =mutateOneAb(currentClone, Firefly)\n",
    "#cloneSet.append(clone_firefly)\n",
    "print(\"\\n*******************!!!!!!!!!!!FİRE!!!!!!!!!!!!!*********-------Firefly=\\n\",Firefly)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "def reregular(file):\n",
    "    S_all=file\n",
    "    S_all['gender']= label_encoder.fit_transform(S_all['gender'])\n",
    "    S_all['ever_married']= label_encoder.fit_transform(S_all['ever_married'])\n",
    "    S_all['work_type']= label_encoder.fit_transform(S_all['work_type'])\n",
    "    S_all['Residence_type']= label_encoder.fit_transform(S_all['Residence_type'])\n",
    "    S_all['avg_glucose_level']= label_encoder.fit_transform(S_all['avg_glucose_level'])\n",
    "    S_all['id']= label_encoder.fit_transform(S_all['id'])\n",
    "    S_all['age']= label_encoder.fit_transform(S_all['age'])\n",
    "    S_all['bmi']= label_encoder.fit_transform(S_all['bmi'])\n",
    "    S_all['smoking_status']= label_encoder.fit_transform(S_all['smoking_status'])\n",
    "    S_all['hypertension']= label_encoder.fit_transform(S_all['hypertension'])\n",
    "    S_all['heart_disease']= label_encoder.fit_transform(S_all['heart_disease'])\n",
    "    file=S_all\n",
    "    return file\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "####S_min All train stroke\n",
    "import random\n",
    "import csv\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import operator\n",
    "import numpy as np\n",
    "from fireflyalgorithm import FireflyAlgorithm\n",
    "k=3\n",
    "\n",
    "def makeAbSortedDF(abPoolList):\n",
    "    abSortedPool = pd.DataFrame(abPoolList)\n",
    "    abSortedPool.columns = df_ab.columns\n",
    "    return abSortedPool\n",
    "\n",
    "\n",
    "def makeAbSortPool(affinityList, abPopulation):\n",
    "    yx = list(zip(affinityList, abPopulation))\n",
    "    print(\"\\nyx before sort:\", yx)\n",
    "    sortedAb = sorted(yx, key=operator.itemgetter(0))\n",
    "    print(\"\\nyx after sort:\", sortedAb)\n",
    "    abPool_sorted = [x for y, x in sortedAb]\n",
    "    return abPool_sorted\n",
    "\n",
    "def selectHighest_n(abPoolSortedDF, n):\n",
    "    abPoolSortedDF_n = abPoolSortedDF[(abPoolSortedDF.index < n)]\n",
    "    return abPoolSortedDF_n\n",
    "# Creates antibodies or antigen population\n",
    "def instantiate_population(PoolList):\n",
    "    # list of antibodies as objects\n",
    "    populationList = []\n",
    "    #print(\"**********************************poolList: \", PoolList)\n",
    "    for vector in PoolList:\n",
    "        # Class Antibody creates Ab or Ag (similar structure)\n",
    "        populationList.append(Antibody(vector))\n",
    "    return populationList\n",
    "for g in range(k):\n",
    "    df_ab=pd.read_csv(\"train{}_stroke_80.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    df_ag=pd.read_csv(\"train{}_stroke_20.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    if (__name__ == \"__main__\"):\n",
    "        # n = int(input(\"Enter 'n' : \"))\n",
    "        # beta = float(input(\"Enter beta : \"))\n",
    "        cfg = configparser.ConfigParser()\n",
    "        cfg.read(\"config.ini\")\n",
    "        beta = cfg.getfloat(\"general\", \"beta\")  # Clone Factor\n",
    "        #d = cfg.getint(\"general\",\"d\")\n",
    "        G = cfg.getint(\"general\", \"G\")  # Number of generations\n",
    "        # thresholdAff = cfg.getfloat(\"general\",\"threshold_affinity\")\n",
    "        #abPopulation\n",
    "        #min\n",
    "        #df_ab = major_antigen\n",
    "        # df_ag = pd.DataFrame(agPopulation)\n",
    "        abPoolList = df_ab.values.tolist()\n",
    "        abPopulation = instantiate_population(abPoolList)\n",
    "        # n = len(abPopulation)//3\n",
    "        n = cfg.getint(\"general\", \"n\")\n",
    "        # output labelled Ag\n",
    "        labelledVectorsList = []\n",
    "        #B_stroke\n",
    "        #df_ag = major_anticor\n",
    "        agPoolList = df_ag.values.tolist()\n",
    "        # print(\"agPoolList: \",agPoolList)\n",
    "        agPopulation = instantiate_population(agPoolList)\n",
    "\n",
    "        ##_id,gender,purchase_total_compared_customer,expensive_items,card_present,swipe_or_chip,sign_or_pin,freq_recent_purchase,easy_resale_items,geodist_deviation,smoking_status,stroke\n",
    "        # agPopulation = [[11,20,30,15,1,1,1,60,50,1,1,1,10,1,1],[12,90,60,30,0,0,1,40,80,50,1,0,50,30,0]]\n",
    "\n",
    "        N = len(agPoolList)\n",
    "        # for generation in range(G):\n",
    "        for i in range(N):\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            #print(\"Current Ag : \", agPopulation[i].toString())\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            # for i in range(len(agPopulation)): #for each antigen Ag do\n",
    "            for generation in range(G):\n",
    "                affinityList = []\n",
    "               # print(           \"----------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "               # print(\"Generation #\", generation + 1)\n",
    "                #print(\"-----------------------------------------------------------------------------------------\")\n",
    "                #print(\"\\nAg Population Size:\\n\", len(agPopulation))\n",
    "                #print(\"\\nAg #:\\n\", i + 1)\n",
    "\n",
    "                # print(\"\\nTop Affinity Antibody in present Generation: \",affinity(agPopulation[i],abPoolSortedList[0],\"cosine\"))\n",
    "                #CHANGEEEE\n",
    "                for j in range(0, len(df_ab.index)):\n",
    "                    affinityList.append(affinity(agPopulation[i], abPopulation[j], \"cosine\"))\n",
    "\n",
    "                    # keep in mind that the affinity here is literally the distance. So More the distance, lesser the affinity\n",
    "                    # might have to consider doing (1 - distance) for affinity later\n",
    "\n",
    "               # print(\"\\nAffinity List: \", affinityList)\n",
    "                abPoolSortedList = makeAbSortPool(affinityList, abPopulation)\n",
    "                #print(\"\\nSorted AntiBodies: \", abPoolSortedList)\n",
    "\n",
    "                # Selecting n highest affinity Ab\n",
    "                top_n = abPoolSortedList[:n]\n",
    "                # print(top_n)\n",
    "                cloneSet = []\n",
    "                currentClonesList = []\n",
    "                for z in range(0, n):\n",
    "                    currentAb = top_n[z]\n",
    "                    # --------------------------Cloning Step----------------------------- #\n",
    "                    x = (beta * N) // (z + 1)\n",
    "                    # x =1\n",
    "\n",
    "                    for l in range(int(x)):\n",
    "                        newClone = currentAb.clone()\n",
    "                        currentClonesList.append(newClone)\n",
    "                   # print(\"\\nCurrent clones after cloning: \\n\", currentClonesList)\n",
    "                    # --------------------------Mutation Step----------------------------- #\n",
    "                    for currentClone in currentClonesList:\n",
    "                        cloneSet.append(mutateOneAb(currentClone, (z + 1) / n))\n",
    "                        # mutation doest alter tid so we might get duplicates\n",
    "                    #print(\"*****CLONESET*********CLONESET**********CLONESET*************CLONESET*************CLONESET*************CLONESET*****CLONESET*************CLONESET*******\")\n",
    "                    #print(\"\\nMutated Clones (current clone set): \\n\", cloneSet)\n",
    "\n",
    "\n",
    "                    #------------------Clone Set Compare and Union with Memory Pool--------#\n",
    "                    #------------------Get Ab p with highest affinity p’ from C S----------#\n",
    "                    ####-------------------HyperParameter Steps---------------------------------#\n",
    "\n",
    "                    #####FIREFLY AlGORITHMMMMMMMMMMMM#######\n",
    "\n",
    "                    def fire_func(x):\n",
    "                        return np.sum(x ** 2)\n",
    "\n",
    "\n",
    "\n",
    "                    FA = FireflyAlgorithm()\n",
    "                    r=random.randint(280,330)\n",
    "                    l=random.uniform(1.5,1.6)\n",
    "                    Firefly=FA.run(function=fire_func, dim=1, lb=l, ub=2, max_evals=r)\n",
    "\n",
    "                    #clone_firefly =mutateOneAb(currentClone, Firefly)\n",
    "                    #cloneSet.append(clone_firefly)\n",
    "                    print(\"\\n*******************!!!!!!!!!!!FİRE!!!!!!!!!!!!!*********-------Firefly=\\n\",Firefly)\n",
    "                    print(\"\\nMutated Clones (current clone set): \\n\",cloneSet)\n",
    "                    print(r)\n",
    "                    print(\"Current Ag : \",agPopulation[i].toString())\n",
    "\n",
    "                    #highestCloneAff = 1\n",
    "                    highestCloneAff =1\n",
    "                    for clone in cloneSet:\n",
    "                        currentCloneAff = affinity(agPopulation[i],clone,\"cosine\")\n",
    "                        if (highestCloneAff > currentCloneAff):\n",
    "                            highestCloneAff = currentCloneAff\n",
    "                            highestAffClone = clone\n",
    "                    print(\"\\nHighest Affinity Clone (Affinity - \",highestCloneAff,\") in current clone set: \\n\",highestAffClone.toString())\n",
    "                    #------------------Get Ab q with highest affinity q’ from---------------#\n",
    "                    #highestMemAbAff = 1\n",
    "                    ####!!!!!!!!!!!!>>>>>\n",
    "                    highestMemAbAff =Firefly\n",
    "                    for ab in abPopulation:\n",
    "                        currentMemAbAff = affinity(agPopulation[i],ab,\"cosine\")\n",
    "                        if (highestMemAbAff > currentMemAbAff and currentMemAbAff>1):\n",
    "                            highestMemAbAff = currentMemAbAff\n",
    "                            # highestAffMemAbIndex =\n",
    "                            highestAffMemAb = ab\n",
    "                    print(\"\\nHighest Affinity Antibody (Affinity - \",highestMemAbAff,\") from Memorty Pool: \\n\",highestAffMemAb.toString())\n",
    "                    #------------------If p’ is greater than q’ replace q per p------------#\n",
    "                    print(\"highestCloneAffhighestCloneAffhighestCloneAff\",highestCloneAff)\n",
    "                    print(\"highestMemAbAffhighestMemAbAffhighestMemAbAff\",highestMemAbAff)\n",
    "                    if (highestCloneAff < highestMemAbAff):\n",
    "                        print(\"START\")\n",
    "                        #abPopulation.remove(highestAffMemAb)\n",
    "                        abPopulation.append(clone)\n",
    "                        print(\"\\n****!!!STARTSTARTSTARTSTART****\\n\")\n",
    "                        print(\"Replaced Antibody from Memory Pool:\\n\", highestAffMemAb.toString())\n",
    "                        print(\"\\n CAME:::: Replaced with clone:\\n\", highestAffClone.toString())\n",
    "                    else:\n",
    "                        print(\"\\n****NO REPLACEMENT*****\\n\")\n",
    "\n",
    "                classificationDone = False\n",
    "\n",
    "                # Once Classification is done go to next antigen to classify\n",
    "                if (classificationDone):\n",
    "                    break\n",
    "\n",
    "        print(\"\\n%%%%%%%The Antibody Pool after the Algorithm%%%%%%%\\n\")\n",
    "        with open(\"train{}_s_min.csv\".format(g+1), 'a') as f_object:\n",
    "\n",
    "            header = [\"id\", \"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
    "                      \"avg_glucose_level\", \"smoking_status\",\"bmi\", \"stroke\"]\n",
    "            dw = csv.DictWriter(f_object, delimiter=',',\n",
    "                                fieldnames=header)\n",
    "            dw.writeheader()\n",
    "            writer_object = writer(f_object)\n",
    "\n",
    "            for ab in abPopulation:\n",
    "                print(ab.toString())\n",
    "                # Pass the list as an argument into\n",
    "                # the writerow()\n",
    "                writer_object.writerow(\n",
    "                    [ab.id, ab.gender, ab.age, ab.hypertension, ab.heart_disease, ab.ever_married, ab.work_type,\n",
    "                     ab.Residence_type, ab.avg_glucose_level, ab.smoking_status, ab.bmi, ab.stroke])\n",
    "            # Close the file object\n",
    "            f_object.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "####S_maj All train unstroke\n",
    "import random\n",
    "import csv\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import operator\n",
    "import numpy as np\n",
    "from fireflyalgorithm import FireflyAlgorithm\n",
    "k=3\n",
    "\n",
    "def makeAbSortedDF(abPoolList):\n",
    "    abSortedPool = pd.DataFrame(abPoolList)\n",
    "    abSortedPool.columns = df_ab.columns\n",
    "    return abSortedPool\n",
    "\n",
    "\n",
    "def makeAbSortPool(affinityList, abPopulation):\n",
    "    yx = list(zip(affinityList, abPopulation))\n",
    "    print(\"\\nyx before sort:\", yx)\n",
    "    sortedAb = sorted(yx, key=operator.itemgetter(0))\n",
    "    print(\"\\nyx after sort:\", sortedAb)\n",
    "    abPool_sorted = [x for y, x in sortedAb]\n",
    "    return abPool_sorted\n",
    "\n",
    "def selectHighest_n(abPoolSortedDF, n):\n",
    "    abPoolSortedDF_n = abPoolSortedDF[(abPoolSortedDF.index < n)]\n",
    "    return abPoolSortedDF_n\n",
    "# Creates antibodies or antigen population\n",
    "def instantiate_population(PoolList):\n",
    "    # list of antibodies as objects\n",
    "    populationList = []\n",
    "    #print(\"**********************************poolList: \", PoolList)\n",
    "    for vector in PoolList:\n",
    "        # Class Antibody creates Ab or Ag (similar structure)\n",
    "        populationList.append(Antibody(vector))\n",
    "    return populationList\n",
    "for g in range(k):\n",
    "    df_ab=pd.read_csv(\"train{}_unstroke_80.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    df_ag=pd.read_csv(\"train{}_unstroke_20.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    if (__name__ == \"__main__\"):\n",
    "        # n = int(input(\"Enter 'n' : \"))\n",
    "        # beta = float(input(\"Enter beta : \"))\n",
    "        cfg = configparser.ConfigParser()\n",
    "        cfg.read(\"config.ini\")\n",
    "        beta = cfg.getfloat(\"general\", \"beta\")  # Clone Factor\n",
    "        #d = cfg.getint(\"general\",\"d\")\n",
    "        G = cfg.getint(\"general\", \"G\")  # Number of generations\n",
    "        # thresholdAff = cfg.getfloat(\"general\",\"threshold_affinity\")\n",
    "        #abPopulation\n",
    "        #min\n",
    "        #df_ab = major_antigen\n",
    "        # df_ag = pd.DataFrame(agPopulation)\n",
    "        abPoolList = df_ab.values.tolist()\n",
    "        abPopulation = instantiate_population(abPoolList)\n",
    "        # n = len(abPopulation)//3\n",
    "        n = cfg.getint(\"general\", \"n\")\n",
    "        # output labelled Ag\n",
    "        labelledVectorsList = []\n",
    "        #B_stroke\n",
    "        #df_ag = major_anticor\n",
    "        agPoolList = df_ag.values.tolist()\n",
    "        # print(\"agPoolList: \",agPoolList)\n",
    "        agPopulation = instantiate_population(agPoolList)\n",
    "\n",
    "        ##_id,gender,purchase_total_compared_customer,expensive_items,card_present,swipe_or_chip,sign_or_pin,freq_recent_purchase,easy_resale_items,geodist_deviation,smoking_status,stroke\n",
    "        # agPopulation = [[11,20,30,15,1,1,1,60,50,1,1,1,10,1,1],[12,90,60,30,0,0,1,40,80,50,1,0,50,30,0]]\n",
    "\n",
    "        N = len(agPoolList)\n",
    "        # for generation in range(G):\n",
    "        for i in range(N):\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            #print(\"Current Ag : \", agPopulation[i].toString())\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            # for i in range(len(agPopulation)): #for each antigen Ag do\n",
    "            for generation in range(G):\n",
    "                affinityList = []\n",
    "                # print(           \"----------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                # print(\"Generation #\", generation + 1)\n",
    "                #print(\"-----------------------------------------------------------------------------------------\")\n",
    "                #print(\"\\nAg Population Size:\\n\", len(agPopulation))\n",
    "                #print(\"\\nAg #:\\n\", i + 1)\n",
    "\n",
    "                # print(\"\\nTop Affinity Antibody in present Generation: \",affinity(agPopulation[i],abPoolSortedList[0],\"cosine\"))\n",
    "                #CHANGEEEE\n",
    "                for j in range(0, len(df_ab.index)):\n",
    "                    affinityList.append(affinity(agPopulation[i], abPopulation[j], \"cosine\"))\n",
    "\n",
    "                    # keep in mind that the affinity here is literally the distance. So More the distance, lesser the affinity\n",
    "                    # might have to consider doing (1 - distance) for affinity later\n",
    "\n",
    "                # print(\"\\nAffinity List: \", affinityList)\n",
    "                abPoolSortedList = makeAbSortPool(affinityList, abPopulation)\n",
    "                #print(\"\\nSorted AntiBodies: \", abPoolSortedList)\n",
    "\n",
    "                # Selecting n highest affinity Ab\n",
    "                top_n = abPoolSortedList[:n]\n",
    "                # print(top_n)\n",
    "                cloneSet = []\n",
    "                currentClonesList = []\n",
    "                for z in range(0, n):\n",
    "                    currentAb = top_n[z]\n",
    "                    # --------------------------Cloning Step----------------------------- #\n",
    "                    x = (beta * N) // (z + 1)\n",
    "                    # x =1\n",
    "\n",
    "                    for l in range(int(x)):\n",
    "                        newClone = currentAb.clone()\n",
    "                        currentClonesList.append(newClone)\n",
    "                    # print(\"\\nCurrent clones after cloning: \\n\", currentClonesList)\n",
    "                    # --------------------------Mutation Step----------------------------- #\n",
    "                    for currentClone in currentClonesList:\n",
    "                        cloneSet.append(mutateOneAb(currentClone, (z + 1) / n))\n",
    "                        # mutation doest alter tid so we might get duplicates\n",
    "                    #print(\"*****CLONESET*********CLONESET**********CLONESET*************CLONESET*************CLONESET*************CLONESET*****CLONESET*************CLONESET*******\")\n",
    "                    #print(\"\\nMutated Clones (current clone set): \\n\", cloneSet)\n",
    "\n",
    "\n",
    "                    #------------------Clone Set Compare and Union with Memory Pool--------#\n",
    "                    #------------------Get Ab p with highest affinity p’ from C S----------#\n",
    "                    ####-------------------HyperParameter Steps---------------------------------#\n",
    "\n",
    "                    #####FIREFLY AlGORITHMMMMMMMMMMMM#######\n",
    "\n",
    "                    def fire_func(x):\n",
    "                        return np.sum(x ** 2)\n",
    "\n",
    "\n",
    "\n",
    "                    FA = FireflyAlgorithm()\n",
    "                    r=random.randint(280,330)\n",
    "                    l=random.uniform(1.5,1.6)\n",
    "                    Firefly=FA.run(function=fire_func, dim=1, lb=l, ub=2, max_evals=r)\n",
    "\n",
    "                    #clone_firefly =mutateOneAb(currentClone, Firefly)\n",
    "                    #cloneSet.append(clone_firefly)\n",
    "                    print(\"\\n*******************!!!!!!!!!!!FİRE!!!!!!!!!!!!!*********-------Firefly=\\n\",Firefly)\n",
    "                    print(\"\\nMutated Clones (current clone set): \\n\",cloneSet)\n",
    "                    print(r)\n",
    "                    print(\"Current Ag : \",agPopulation[i].toString())\n",
    "\n",
    "                    #highestCloneAff = 1\n",
    "                    highestCloneAff =1\n",
    "                    for clone in cloneSet:\n",
    "                        currentCloneAff = affinity(agPopulation[i],clone,\"cosine\")\n",
    "                        if (highestCloneAff > currentCloneAff):\n",
    "                            highestCloneAff = currentCloneAff\n",
    "                            highestAffClone = clone\n",
    "                    print(\"\\nHighest Affinity Clone (Affinity - \",highestCloneAff,\") in current clone set: \\n\",highestAffClone.toString())\n",
    "                    #------------------Get Ab q with highest affinity q’ from---------------#\n",
    "                    #highestMemAbAff = 1\n",
    "                    ####!!!!!!!!!!!!>>>>>\n",
    "                    highestMemAbAff =Firefly\n",
    "                    for ab in abPopulation:\n",
    "                        currentMemAbAff = affinity(agPopulation[i],ab,\"cosine\")\n",
    "                        if (highestMemAbAff > currentMemAbAff and currentMemAbAff>1):\n",
    "                            highestMemAbAff = currentMemAbAff\n",
    "                            # highestAffMemAbIndex =\n",
    "                            highestAffMemAb = ab\n",
    "                    print(\"\\nHighest Affinity Antibody (Affinity - \",highestMemAbAff,\") from Memorty Pool: \\n\",highestAffMemAb.toString())\n",
    "                    #------------------If p’ is greater than q’ replace q per p------------#\n",
    "                    print(\"highestCloneAffhighestCloneAffhighestCloneAff\",highestCloneAff)\n",
    "                    print(\"highestMemAbAffhighestMemAbAffhighestMemAbAff\",highestMemAbAff)\n",
    "                    if (highestCloneAff < highestMemAbAff):\n",
    "                        print(\"START\")\n",
    "                        #abPopulation.remove(highestAffMemAb)\n",
    "                        abPopulation.append(clone)\n",
    "                        print(\"\\n****!!!STARTSTARTSTARTSTART****\\n\")\n",
    "                        print(\"Replaced Antibody from Memory Pool:\\n\", highestAffMemAb.toString())\n",
    "                        print(\"\\n CAME:::: Replaced with clone:\\n\", highestAffClone.toString())\n",
    "                    else:\n",
    "                        print(\"\\n****NO REPLACEMENT*****\\n\")\n",
    "\n",
    "                classificationDone = False\n",
    "\n",
    "                # Once Classification is done go to next antigen to classify\n",
    "                if (classificationDone):\n",
    "                    break\n",
    "\n",
    "        print(\"\\n%%%%%%%The Antibody Pool after the Algorithm%%%%%%%\\n\")\n",
    "        with open(\"train{}_s_maj.csv\".format(g+1), 'a') as f_object:\n",
    "\n",
    "            header = [\"id\", \"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
    "                      \"avg_glucose_level\", \"smoking_status\",\"bmi\", \"stroke\"]\n",
    "            dw = csv.DictWriter(f_object, delimiter=',',\n",
    "                                fieldnames=header)\n",
    "            dw.writeheader()\n",
    "            writer_object = writer(f_object)\n",
    "\n",
    "            for ab in abPopulation:\n",
    "                print(ab.toString())\n",
    "                # Pass the list as an argument into\n",
    "                # the writerow()\n",
    "                writer_object.writerow(\n",
    "                    [ab.id, ab.gender, ab.age, ab.hypertension, ab.heart_disease, ab.ever_married, ab.work_type,\n",
    "                     ab.Residence_type, ab.avg_glucose_level, ab.smoking_status, ab.bmi, ab.stroke])\n",
    "            # Close the file object\n",
    "            f_object.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "#Smin+Smaj create sum 3 files AIS with train1,rain2,train3\n",
    "####S_maj All train unstroke\n",
    "import random\n",
    "import csv\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import operator\n",
    "import numpy as np\n",
    "from fireflyalgorithm import FireflyAlgorithm\n",
    "k=3\n",
    "\n",
    "def makeAbSortedDF(abPoolList):\n",
    "    abSortedPool = pd.DataFrame(abPoolList)\n",
    "    abSortedPool.columns = df_ab.columns\n",
    "    return abSortedPool\n",
    "\n",
    "\n",
    "def makeAbSortPool(affinityList, abPopulation):\n",
    "    yx = list(zip(affinityList, abPopulation))\n",
    "    print(\"\\nyx before sort:\", yx)\n",
    "    sortedAb = sorted(yx, key=operator.itemgetter(0))\n",
    "    print(\"\\nyx after sort:\", sortedAb)\n",
    "    abPool_sorted = [x for y, x in sortedAb]\n",
    "    return abPool_sorted\n",
    "\n",
    "def selectHighest_n(abPoolSortedDF, n):\n",
    "    abPoolSortedDF_n = abPoolSortedDF[(abPoolSortedDF.index < n)]\n",
    "    return abPoolSortedDF_n\n",
    "# Creates antibodies or antigen population\n",
    "def instantiate_population(PoolList):\n",
    "    # list of antibodies as objects\n",
    "    populationList = []\n",
    "    #print(\"**********************************poolList: \", PoolList)\n",
    "    for vector in PoolList:\n",
    "        # Class Antibody creates Ab or Ag (similar structure)\n",
    "        populationList.append(Antibody(vector))\n",
    "    return populationList\n",
    "for g in range(k):\n",
    "    df_ab=pd.read_csv(\"train{}_S_all.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    df_ag=pd.read_csv(\"train{}.csv\".format(g+1))\n",
    "    #df_ab=reregular(df_ab)\n",
    "\n",
    "    if (__name__ == \"__main__\"):\n",
    "        # n = int(input(\"Enter 'n' : \"))\n",
    "        # beta = float(input(\"Enter beta : \"))\n",
    "        cfg = configparser.ConfigParser()\n",
    "        cfg.read(\"config.ini\")\n",
    "        beta = cfg.getfloat(\"general\", \"beta\")  # Clone Factor\n",
    "        #d = cfg.getint(\"general\",\"d\")\n",
    "        G = cfg.getint(\"general\", \"G\")  # Number of generations\n",
    "        # thresholdAff = cfg.getfloat(\"general\",\"threshold_affinity\")\n",
    "        #abPopulation\n",
    "        #min\n",
    "        #df_ab = major_antigen\n",
    "        # df_ag = pd.DataFrame(agPopulation)\n",
    "        abPoolList = df_ab.values.tolist()\n",
    "        abPopulation = instantiate_population(abPoolList)\n",
    "        # n = len(abPopulation)//3\n",
    "        n = cfg.getint(\"general\", \"n\")\n",
    "        # output labelled Ag\n",
    "        labelledVectorsList = []\n",
    "        #B_stroke\n",
    "        #df_ag = major_anticor\n",
    "        agPoolList = df_ag.values.tolist()\n",
    "        # print(\"agPoolList: \",agPoolList)\n",
    "        agPopulation = instantiate_population(agPoolList)\n",
    "\n",
    "        ##_id,gender,purchase_total_compared_customer,expensive_items,card_present,swipe_or_chip,sign_or_pin,freq_recent_purchase,easy_resale_items,geodist_deviation,smoking_status,stroke\n",
    "        # agPopulation = [[11,20,30,15,1,1,1,60,50,1,1,1,10,1,1],[12,90,60,30,0,0,1,40,80,50,1,0,50,30,0]]\n",
    "\n",
    "        N = len(agPoolList)\n",
    "        # for generation in range(G):\n",
    "        for i in range(N):\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            #print(\"Current Ag : \", agPopulation[i].toString())\n",
    "            #print(\"-----------------------------------------------------------------------\")\n",
    "            # for i in range(len(agPopulation)): #for each antigen Ag do\n",
    "            for generation in range(G):\n",
    "                affinityList = []\n",
    "                # print(           \"----------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                # print(\"Generation #\", generation + 1)\n",
    "                #print(\"-----------------------------------------------------------------------------------------\")\n",
    "                #print(\"\\nAg Population Size:\\n\", len(agPopulation))\n",
    "                #print(\"\\nAg #:\\n\", i + 1)\n",
    "\n",
    "                # print(\"\\nTop Affinity Antibody in present Generation: \",affinity(agPopulation[i],abPoolSortedList[0],\"cosine\"))\n",
    "                #CHANGEEEE\n",
    "                for j in range(0, len(df_ab.index)):\n",
    "                    affinityList.append(affinity(agPopulation[i], abPopulation[j], \"cosine\"))\n",
    "\n",
    "                    # keep in mind that the affinity here is literally the distance. So More the distance, lesser the affinity\n",
    "                    # might have to consider doing (1 - distance) for affinity later\n",
    "\n",
    "                # print(\"\\nAffinity List: \", affinityList)\n",
    "                abPoolSortedList = makeAbSortPool(affinityList, abPopulation)\n",
    "                #print(\"\\nSorted AntiBodies: \", abPoolSortedList)\n",
    "\n",
    "                # Selecting n highest affinity Ab\n",
    "                top_n = abPoolSortedList[:n]\n",
    "                # print(top_n)\n",
    "                cloneSet = []\n",
    "                currentClonesList = []\n",
    "                for z in range(0, n):\n",
    "                    currentAb = top_n[z]\n",
    "                    # --------------------------Cloning Step----------------------------- #\n",
    "                    x = (beta * N) // (z + 1)\n",
    "                    # x =1\n",
    "\n",
    "                    for l in range(int(x)):\n",
    "                        newClone = currentAb.clone()\n",
    "                        currentClonesList.append(newClone)\n",
    "                    # print(\"\\nCurrent clones after cloning: \\n\", currentClonesList)\n",
    "                    # --------------------------Mutation Step----------------------------- #\n",
    "                    for currentClone in currentClonesList:\n",
    "                        cloneSet.append(mutateOneAb(currentClone, (z + 1) / n))\n",
    "                        # mutation doest alter tid so we might get duplicates\n",
    "                    #print(\"*****CLONESET*********CLONESET**********CLONESET*************CLONESET*************CLONESET*************CLONESET*****CLONESET*************CLONESET*******\")\n",
    "                    #print(\"\\nMutated Clones (current clone set): \\n\", cloneSet)\n",
    "\n",
    "\n",
    "                    #------------------Clone Set Compare and Union with Memory Pool--------#\n",
    "                    #------------------Get Ab p with highest affinity p’ from C S----------#\n",
    "                    ####-------------------HyperParameter Steps---------------------------------#\n",
    "\n",
    "                    #####FIREFLY AlGORITHMMMMMMMMMMMM#######\n",
    "\n",
    "                    def fire_func(x):\n",
    "                        return np.sum(x ** 2)\n",
    "\n",
    "\n",
    "\n",
    "                    FA = FireflyAlgorithm()\n",
    "                    r=random.randint(280,330)\n",
    "                    l=random.uniform(1.5,1.6)\n",
    "                    Firefly=FA.run(function=fire_func, dim=1, lb=l, ub=2, max_evals=r)\n",
    "\n",
    "                    #clone_firefly =mutateOneAb(currentClone, Firefly)\n",
    "                    #cloneSet.append(clone_firefly)\n",
    "                    print(\"\\n*******************!!!!!!!!!!!FİRE!!!!!!!!!!!!!*********-------Firefly=\\n\",Firefly)\n",
    "                    print(\"\\nMutated Clones (current clone set): \\n\",cloneSet)\n",
    "                    print(r)\n",
    "                    print(\"Current Ag : \",agPopulation[i].toString())\n",
    "\n",
    "                    #highestCloneAff = 1\n",
    "                    highestCloneAff =1\n",
    "                    for clone in cloneSet:\n",
    "                        currentCloneAff = affinity(agPopulation[i],clone,\"cosine\")\n",
    "                        if (highestCloneAff > currentCloneAff):\n",
    "                            highestCloneAff = currentCloneAff\n",
    "                            highestAffClone = clone\n",
    "                    print(\"\\nHighest Affinity Clone (Affinity - \",highestCloneAff,\") in current clone set: \\n\",highestAffClone.toString())\n",
    "                    #------------------Get Ab q with highest affinity q’ from---------------#\n",
    "                    #highestMemAbAff = 1\n",
    "                    ####!!!!!!!!!!!!>>>>>\n",
    "                    highestMemAbAff =Firefly\n",
    "                    for ab in abPopulation:\n",
    "                        currentMemAbAff = affinity(agPopulation[i],ab,\"cosine\")\n",
    "                        if (highestMemAbAff > currentMemAbAff and currentMemAbAff>1):\n",
    "                            highestMemAbAff = currentMemAbAff\n",
    "                            # highestAffMemAbIndex =\n",
    "                            highestAffMemAb = ab\n",
    "                    print(\"\\nHighest Affinity Antibody (Affinity - \",highestMemAbAff,\") from Memorty Pool: \\n\",highestAffMemAb.toString())\n",
    "                    #------------------If p’ is greater than q’ replace q per p------------#\n",
    "                    print(\"highestCloneAffhighestCloneAffhighestCloneAff\",highestCloneAff)\n",
    "                    print(\"highestMemAbAffhighestMemAbAffhighestMemAbAff\",highestMemAbAff)\n",
    "                    if (highestCloneAff < highestMemAbAff):\n",
    "                        print(\"START\")\n",
    "                        #abPopulation.remove(highestAffMemAb)\n",
    "                        abPopulation.append(clone)\n",
    "                        print(\"\\n****!!!STARTSTARTSTARTSTART****\\n\")\n",
    "                        print(\"Replaced Antibody from Memory Pool:\\n\", highestAffMemAb.toString())\n",
    "                        print(\"\\n CAME:::: Replaced with clone:\\n\", highestAffClone.toString())\n",
    "                    else:\n",
    "                        print(\"\\n****NO REPLACEMENT*****\\n\")\n",
    "\n",
    "                classificationDone = False\n",
    "\n",
    "                # Once Classification is done go to next antigen to classify\n",
    "                if (classificationDone):\n",
    "                    break\n",
    "\n",
    "        print(\"\\n%%%%%%%The Antibody Pool after the Algorithm%%%%%%%\\n\")\n",
    "        with open(\"train{}_k_{}.csv\".format(g+1), 'a') as f_object:\n",
    "\n",
    "            header = [\"id\", \"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
    "                      \"avg_glucose_level\", \"smoking_status\",\"bmi\", \"stroke\"]\n",
    "            dw = csv.DictWriter(f_object, delimiter=',',\n",
    "                                fieldnames=header)\n",
    "            dw.writeheader()\n",
    "            writer_object = writer(f_object)\n",
    "\n",
    "            for ab in abPopulation:\n",
    "                print(ab.toString())\n",
    "                # Pass the list as an argument into\n",
    "                # the writerow()\n",
    "                writer_object.writerow(\n",
    "                    [ab.id, ab.gender, ab.age, ab.hypertension, ab.heart_disease, ab.ever_married, ab.work_type,\n",
    "                     ab.Residence_type, ab.avg_glucose_level, ab.smoking_status, ab.bmi, ab.stroke])\n",
    "            # Close the file object\n",
    "            f_object.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "#Regular all datas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#balanced 3 train datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###CLASSIFICATION WITHOUT ABC  and create metricss****###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "syc=0\n",
    "df = data\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "#Implementing cross validation\n",
    "#lab = preprocessing.LabelEncoder()\n",
    "#y= lab.fit_transform(y)\n",
    "k = 2\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model =  XGBClassifier()\n",
    "acc_score = []\n",
    "spec_score=[]\n",
    "sens_score=[]\n",
    "gmean_score=[]\n",
    "print(\"kf.split(X)kf.split(X)kf.split(X)\",kf.split(X))\n",
    "for train_index , test_index in kf.split(X):\n",
    "\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "    syc=syc+1\n",
    "    print(\"sycsyc\",syc)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    #########ACCURACY########\n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "    cm1=metrics.confusion_matrix(y_test, pred_values)\n",
    "    total1=(cm1[0,0]+cm1[1,1]+cm1[1,0]+cm1[0,1])\n",
    "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    ##sensivity#####\n",
    "    sens = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print('svm Sensitivity : ', sens )\n",
    "    sens_score.append(sens)\n",
    "    ##specifity######\n",
    "    spec = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print('svm Specificity : ', spec)\n",
    "    spec_score.append(spec)\n",
    "    #####geometric mean sens_score######\n",
    "    geo=geometric_mean_score(pred_values , y_test)\n",
    "    print('The geometric mean is ',geo)\n",
    "    gmean_score.append(geo)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_spec_score = sum(spec_score)/k\n",
    "avg_sens_score = sum(sens_score)/k\n",
    "avg_gmean_score = sum(gmean_score)/k\n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
